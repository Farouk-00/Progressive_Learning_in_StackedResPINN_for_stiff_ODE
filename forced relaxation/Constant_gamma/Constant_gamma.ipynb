{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.Module):\n",
    "    \"\"\"\n",
    "    Multi-Layer Perceptron (MLP) class with regularization handling.\n",
    "\n",
    "    --------------\n",
    "    insize: input size (int)\n",
    "    outsize: output size (int)\n",
    "    hsize: A list specifying the number of neurons in each hidden layer (list of ints).\n",
    "    bias: Boolean indicating whether to include a bias term in the linear layers (default: True)\n",
    "    nonlin: The activation function to be used in the hidden layers (default: nn.Tanh).\n",
    "    linear_map:  The type of linear transformation to be used (default: nn.Linear)\n",
    "    \"\"\"\n",
    "    def __init__(self, insize, outsize, hsizes, bias=True, nonlin=tf.tanh, linear_map=tf.keras.layers.Dense):\n",
    "        super().__init__()\n",
    "        self.in_features, self.out_features = insize, outsize\n",
    "        self.nhidden = len(hsizes)\n",
    "        self.layers = []\n",
    "        self.nonlin = []\n",
    "        self.seed = 123\n",
    "        # Create linear layers and activation functions\n",
    "        layer_sizes = [insize] + hsizes + [outsize]\n",
    "        for k in range(len(layer_sizes) - 1):\n",
    "            initializer = tf.keras.initializers.GlorotUniform(self.seed+k)\n",
    "            self.layers.append(linear_map(units=layer_sizes[k+1], use_bias=bias, kernel_initializer=initializer))\n",
    "            if k < self.nhidden:\n",
    "                self.nonlin.append(nonlin)\n",
    "            else:\n",
    "                self.nonlin.append(tf.identity)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for i in range(len(self.layers)):\n",
    "            x = self.nonlin[i](self.layers[i](x))\n",
    "        return x\n",
    "\n",
    "    def reg_error(self):\n",
    "        \"\"\"\n",
    "        Compute the regularization error for the linear layers that support it.\n",
    "        \"\"\"\n",
    "        reg_loss = 0.0\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, \"reg_error\"):\n",
    "                reg_loss += layer.reg_error()\n",
    "        return reg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(tf.Module):\n",
    "    \"\"\"\n",
    "    A single ResNet block that takes the current output (from the previous layer or from the single-fidelity model)\n",
    "    and the original input x, and learns a residual mapping.\n",
    "\n",
    "    The block computes:\n",
    "    out_new = out_old + alpha * F(x)\n",
    "\n",
    "    F is implemented by an MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim_x, in_dim_out, hres_sizes=[20, 20], bias=True, nonlin=tf.tanh):\n",
    "        \"\"\"\n",
    "        in_dim_x : int, dimension of input x\n",
    "        in_dim_out : int, dimension of the output (u)\n",
    "        hres_sizes : list of ints, hidden layer sizes for the residual MLP\n",
    "        bias : bool, whether to include bias in MLP layers\n",
    "        nonlin : activation function class (e.g., nn.Tanh)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.res_mlp = MLP(in_dim_x, in_dim_out, hsizes=hres_sizes, bias=bias, nonlin=nonlin)\n",
    "\n",
    "    def __call__(self, x, out_old, alpha):\n",
    "        \"\"\"\n",
    "        Forward pass of the ResNet block.\n",
    "\n",
    "        x: tensor of shape (N, in_dim_x)\n",
    "        out_old: tensor of shape (N, in_dim_out)\n",
    "        alpha: scalar parameter controlling the amplitude of the residual update.\n",
    "\n",
    "        return: out_new = out_old + alpha * F(x)\n",
    "        \"\"\"\n",
    "        residual = self.res_mlp(x)\n",
    "        out_new = out_old + tf.abs(alpha) * residual\n",
    "        return out_new\n",
    "\n",
    "# Define the Stacked MLP class for Stacked PINN with ResNet blocks\n",
    "class StackedMLP(tf.Module):\n",
    "    \"\"\"\n",
    "    Stacked Multi-Layer Perceptron designed for multi-fidelity learning where multiple layers are\n",
    "    stacked to refine the prediction progressively. Now, each stacked layer is a ResNet block.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        insize,\n",
    "        outsize,\n",
    "        h_sf_sizes=[20, 20], # The single fidelity hidden size\n",
    "        n_stacked_mf_layers=3,\n",
    "        # The residual block hidden sizes for each stacked layer\n",
    "        h_res_sizes=[20,20,20],\n",
    "        bias=True,\n",
    "        nonlin=tf.tanh,\n",
    "        alpha_init=0.1,\n",
    "        u_initial=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.insize = insize\n",
    "        self.outsize = outsize\n",
    "        self.h_sf_sizes = h_sf_sizes\n",
    "        self.n_stacked_mf_layers = n_stacked_mf_layers\n",
    "        self.h_res_sizes = h_res_sizes\n",
    "        self.bias = bias\n",
    "        self.nonlin = nonlin\n",
    "        self.alpha_init = alpha_init\n",
    "        \n",
    "        if u_initial is None:\n",
    "            self.u0 = tf.zeros(shape=(outsize, 1), dtype=tf.float32)\n",
    "        else:\n",
    "            self.u0 = u_initial\n",
    "\n",
    "        # Initial single-fidelity MLP\n",
    "        self.first_layer = MLP(insize, outsize, hsizes=h_sf_sizes, bias=bias, nonlin=nonlin)\n",
    "\n",
    "        # Alpha parameters, one per stacked layer\n",
    "        self.alpha = [tf.Variable(0.0, trainable=True)] + [tf.Variable(alpha_init, trainable=True) for _ in range(n_stacked_mf_layers)]\n",
    "\n",
    "        # Considering each stacked layer as a ResNet block\n",
    "        self.layers = []\n",
    "        for _ in range(n_stacked_mf_layers):\n",
    "            res_block = ResNetBlock(insize, outsize, hres_sizes=self.h_res_sizes, bias=bias, nonlin=nonlin)\n",
    "            self.layers.append(res_block)\n",
    "\n",
    "    def __call__(self, x, i=None):\n",
    "        if i is None:\n",
    "            i = self.n_stacked_mf_layers\n",
    "        i = min(i, self.n_stacked_mf_layers)\n",
    "\n",
    "        # First layer (single-fidelity MLP)\n",
    "        out = self.first_layer(x)\n",
    "        out_old = tf.zeros_like(out)\n",
    "        residual = out\n",
    "        \n",
    "        # Apply stacked ResNet blocks up to layer i\n",
    "        for j in range(i):\n",
    "            alpha = self.alpha[j+1]\n",
    "            layer = self.layers[j]\n",
    "            # Each layer: out = out + alpha * res_mlp(x)\n",
    "            out_old = out\n",
    "            out = layer(x, out_old, alpha)\n",
    "            residual = out - out_old\n",
    "        #return out_new, out_old, and residual\n",
    "        return self.u0 + tf.tanh(x) * out, self.u0 + tf.tanh(x) * out_old, tf.tanh(x) * residual\n",
    "\n",
    "    def get_alpha_loss(self, i=None):\n",
    "        \"\"\"\n",
    "        Retrieve the accumulated loss from alpha parameters used for regularization purposes.\n",
    "\n",
    "        :return: Alpha loss as a torch scalar.\n",
    "        \"\"\"\n",
    "        return tf.pow(self.alpha[i], 4)\n",
    "\n",
    "# Analytical solution for the forced relaxation equation\n",
    "def analytical_solution(n_steps, T_max=1, parameters_init=50.0, u_0=0.0):\n",
    "    \"\"\"\n",
    "    Analytical solution of the forced relaxation equation.\n",
    "\n",
    "    Arguments:\n",
    "    - n_steps        : number of time steps\n",
    "    - T_max          : final time\n",
    "    - parameters_init: value of the parameter Î¼ (mu) in the equation\n",
    "    - u_0            : initial condition u(0)\n",
    "\n",
    "    Returns:\n",
    "    - x: analytical trajectory (n_steps,), solution values over time\n",
    "    - t: time array (n_steps,)\n",
    "    \"\"\"\n",
    "    mu = parameters_init\n",
    "    dt = T_max / float(n_steps)\n",
    "    t = np.arange(0, n_steps * dt, dt)\n",
    "    \n",
    "    # Formule exacte\n",
    "    x = (mu**2 * np.cos(t) + mu * np.sin(t)) / (mu**2 + 1) \\\n",
    "        - (mu**2 / (mu**2 + 1)) * np.exp(-mu * t)\n",
    "    \n",
    "    return tf.convert_to_tensor(x, dtype=tf.float32), tf.convert_to_tensor(t, dtype=tf.float32)\n",
    "\n",
    "def l2_relative_error(u_pred, u_true, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Compute L2 relative error between predicted values and true values.\n",
    "\n",
    "    Parameters:\n",
    "    u_pred (Tensor): Predicted values (model output)\n",
    "    u_true (Tensor): True values (ground truth)\n",
    "\n",
    "    Returns:\n",
    "    float: L2 relative error\n",
    "    \"\"\"\n",
    "    u_pred = tf.convert_to_tensor(u_pred, dtype=tf.float32)\n",
    "    u_true = tf.convert_to_tensor(u_true, dtype=tf.float32)\n",
    "\n",
    "    u_pred = tf.reshape(u_pred, [-1])\n",
    "    u_true = tf.reshape(u_true, [-1])\n",
    "\n",
    "    num = tf.norm(u_pred - u_true, ord='euclidean')\n",
    "    denom = tf.norm(u_true, ord='euclidean')\n",
    "    return (num / (denom + eps)).numpy().item()\n",
    "\n",
    "# Define the Stacked PINN class with modifications to store losses\n",
    "class StackedResPINN:\n",
    "    def __init__(self, model, optimizer_primal, optimizer_dual, lr_scheduler=None, patience=100, patience_gamma=1000, N_collocation=1000, N_resample=50, N_dual=10, gammas_init=[], parameters_init=50.0, logger=None, T_max=1):\n",
    "        self.model = model\n",
    "        self.optimizer_primal = optimizer_primal\n",
    "        self.optimizer_dual = optimizer_dual\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.logger = logger\n",
    "        self.n_stacked_layers = model.n_stacked_mf_layers+1  # Number of stacked layers (Using for averaging loss) +1 for vanilla layer 0\n",
    "        self.N_phys = N_collocation\n",
    "        self.N_resample = N_resample\n",
    "        self.N_dual = N_dual\n",
    "        # Early stopping attributes\n",
    "        self.patience = patience\n",
    "        self.patience_gamma = patience_gamma\n",
    "        self.best_loss = 0.0\n",
    "        self.bad_epochs = 0\n",
    "        self.bad_epochs_gamma = 0\n",
    "        \n",
    "        self.T_max = T_max\n",
    "        self.weight = tf.Variable(1.0, dtype=tf.float32)\n",
    "        self.parameters = parameters_init\n",
    "        self.mu = self.parameters\n",
    "\n",
    "        self.epsilon = tf.Variable(1.0e-2, dtype=tf.float32, trainable=False)\n",
    "        self.omegas_t = tf.Variable(tf.zeros((self.n_stacked_layers, N_collocation), dtype=tf.float32), trainable=False)\n",
    "\n",
    "        self.K = 0  # K is the index of the stack being updated\n",
    "        self.update_count = 1\n",
    "\n",
    "        # initialize the sequence alpha and the sitffness sigma of each stack\n",
    "        self.gammas = tf.Variable(initial_value=gammas_init, trainable=False)\n",
    "        self.old_gammas = self.gammas # for early stopping check\n",
    "        self.sigma = tf.Variable(initial_value= (-1.0e-3) * tf.ones([self.n_stacked_layers], dtype=tf.float32),trainable=False)\n",
    "\n",
    "    def resample(self):\n",
    "        t_collocation = tf.random.uniform(shape=(self.N_phys, 1), minval=0, maxval=self.T_max)\n",
    "        return t_collocation\n",
    "\n",
    "\n",
    "    #############################       UPDATE ALPHA        ############################\n",
    "\n",
    "    def cummin(self, x):\n",
    "        \"\"\" \n",
    "        function cummin to force the sequence gamma_i to be nondecreasing:\n",
    "            - takes a sequence a_i as entry\n",
    "            - returns a sequence where each term gamma_i = min(gamma_i, gamma_i+1) begining with the first term\n",
    "        \"\"\"\n",
    "        x = tf.convert_to_tensor(x)\n",
    "        x_list = tf.unstack(x)\n",
    "\n",
    "        out = []\n",
    "        current_min = x_list[0]\n",
    "        out.append(current_min)\n",
    "\n",
    "        for xi in x_list[1:]:\n",
    "            current_min = tf.minimum(current_min, xi)\n",
    "            out.append(current_min)\n",
    "\n",
    "        return tf.stack(out)\n",
    "    \n",
    "    def update_stiffness_indicators(self, t):\n",
    "        \"\"\"\n",
    "        compute the stiffness indicator of each stack at each time t* = = argmin(sigma_N(t))\n",
    "        \"\"\"\n",
    "        # compute the current solution of each stack\n",
    "        u1 = []\n",
    "        for k in range(self.n_stacked_layers):\n",
    "            U, _, _ = self.model(t, i=k)\n",
    "            u1.append(U[:, 0:1])\n",
    "        u1 = tf.squeeze(tf.stack(u1, axis=1), axis=2)\n",
    "\n",
    "        #compute sigma\n",
    "        sigma = -self.parameters + 0.0*u1\n",
    "\n",
    "        # get t* = argmin(sigma_N(t)) and get each sigma_i at t*\n",
    "        last_layer_sigma = sigma[:, -1]\n",
    "        min_index = tf.argmin(last_layer_sigma)\n",
    "        sigma_at_min_index = sigma[min_index, :]\n",
    "        self.sigma.assign(self.cummin(sigma_at_min_index))\n",
    "\n",
    "    def update_gammas(self, smoothing_coef, t):\n",
    "        \"\"\"\n",
    "        updates the sequence gamma_i depending on the stiffness gamma_i of the solution of each stack:\n",
    "            - gamma_i = (i+1)/(N+1) * sigma_N(t*)/sigma_i(t*)\n",
    "            - t* = argmin(sigma_N(t))\n",
    "        \"\"\"\n",
    "        self.update_stiffness_indicators(t)\n",
    "        i_s = tf.cumsum(tf.ones([self.n_stacked_layers], dtype=tf.float32))\n",
    "\n",
    "        # compute each new gamma_i\n",
    "        alpha_i = tf.abs((i_s*self.sigma[-1]) / (self.n_stacked_layers*self.sigma))\n",
    "\n",
    "        new_gammas = tf.minimum(alpha_i, tf.ones([self.n_stacked_layers], dtype=tf.float32))   # force gamma_i to range between 0 and 1\n",
    "        new_gammas = tf.reverse(self.cummin(tf.reverse(new_gammas, axis=[0])), axis=[0]) # prevent each gamma_i to be higher than gamma_(i+1)\n",
    "        new_gammas = tf.stop_gradient((1 - smoothing_coef) * self.gammas + smoothing_coef * new_gammas) # smooth gamma and prevent gradient propagation through its computation\n",
    "        self.gammas.assign(new_gammas)\n",
    "\n",
    "\n",
    "    #############################       LOSS       ############################\n",
    "\n",
    "    def f(self, u1, t, alpha_i):\n",
    "        term1 = self.mu*alpha_i * (tf.cos(t) - u1)\n",
    "        return term1\n",
    "\n",
    "    @tf.function\n",
    "    def loss_function(self, t, k):\n",
    "        \"\"\"\n",
    "        loss function to compute the residual loss of stack k\n",
    "            - k is the index of the stack currently being optimized\n",
    "        \"\"\"\n",
    "        losses = []\n",
    "        omegas_t = []\n",
    "        inp = t\n",
    "\n",
    "        for i in range(self.n_stacked_layers):\n",
    "            if i == k:  # if i is the index of the stack currently being optimized\n",
    "                if i ==0:\n",
    "                    with tf.GradientTape(watch_accessed_variables=False) as tape1:\n",
    "                        tape1.watch(inp)\n",
    "                        U, _, _ = self.model(inp, i=i)\n",
    "                    U_t = tape1.batch_jacobian(U, inp)\n",
    "                    u1 = U[:, 0:1]\n",
    "                    \n",
    "                    f = tf.squeeze(U_t, axis=2) - tf.concat(self.f(u1, t, self.gammas[i]), axis=1)\n",
    "\n",
    "                else:\n",
    "                    with tf.GradientTape(watch_accessed_variables=False) as tape1:\n",
    "                        tape1.watch(inp)\n",
    "                        U, U_old, R = self.model(inp, i=i)\n",
    "                    R_t = tape1.batch_jacobian(R, inp)\n",
    "                    u1 = U[:, 0:1]\n",
    "                    u1_old = U_old[:, 0:1]\n",
    "                    \n",
    "                    f = tf.squeeze(R_t, axis=2) - tf.concat(self.f(u1, t, self.gammas[i]), axis=1) + tf.concat(self.f(u1_old, t, self.gammas[i-1]), axis=1)\n",
    "                \n",
    "                f_squared = tf.square(f)\n",
    "                f_squared_sum = tf.reduce_sum(f_squared, axis=1, keepdims=True)\n",
    "                f_squared_cumsum = tf.cumsum(f_squared_sum, exclusive=True)\n",
    "                omega_t = tf.stop_gradient(tf.exp(-self.epsilon * f_squared_cumsum))\n",
    "                weighted_f_squared = omega_t * f_squared\n",
    "                \n",
    "                ode_i = self.weight * tf.reduce_mean(weighted_f_squared) + self.model.get_alpha_loss(i=i)\n",
    "                \n",
    "            else: # if i is NOT the index of the stack currently being optimized, do not comput loss at this stack\n",
    "                ode_i = 0.0\n",
    "                u1 = tf.zeros_like(inp[:, :1])\n",
    "                if i < k:\n",
    "                    omega_t = tf.stop_gradient(tf.ones((self.N_phys, 1), dtype=tf.float32))\n",
    "                else:\n",
    "                    omega_t = tf.stop_gradient(tf.zeros((self.N_phys, 1), dtype=tf.float32))\n",
    "\n",
    "            omegas_t.append(omega_t)\n",
    "            losses.append(ode_i)\n",
    "\n",
    "        self.omegas_t.assign(tf.squeeze(tf.stack(omegas_t, axis=0), axis=-1))\n",
    "\n",
    "        return losses\n",
    "    \n",
    "    def get_target_variables(self, k):\n",
    "        \"\"\"\n",
    "        get weights and biaises theta of stack k to be optimized\n",
    "        \"\"\"\n",
    "        variables = []\n",
    "        if k == 0:\n",
    "            variables.extend(self.model.first_layer.trainable_variables)\n",
    "        else:\n",
    "            variables.extend(self.model.layers[k-1].trainable_variables)\n",
    "        variables.append(self.model.alpha[k])\n",
    "        return variables\n",
    "\n",
    "    @tf.function\n",
    "    def total_loss(self, t_collocation, k):\n",
    "        physics_loss = self.loss_function(t_collocation, k)\n",
    "        return sum(physics_loss)\n",
    "\n",
    "    @tf.function\n",
    "    def primal_update_k(self, t_collocation, target_variables, k):\n",
    "        with tf.GradientTape(watch_accessed_variables=False) as loss_tape:\n",
    "            loss_tape.watch(target_variables)\n",
    "            loss = self.total_loss(t_collocation, k)\n",
    "        grads = loss_tape.gradient(loss, target_variables)\n",
    "        self.optimizer_primal[k].apply_gradients(zip(grads, target_variables))\n",
    "        return loss\n",
    "    \n",
    "    def primal_update(self, t_collocation):\n",
    "        target_variables = self.get_target_variables(self.K)\n",
    "        loss = self.primal_update_k(t_collocation, target_variables, self.K)\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def dual_update(self, t_collocation):\n",
    "        with tf.GradientTape(watch_accessed_variables=False) as loss_tape:\n",
    "            loss_tape.watch(self.weight)\n",
    "            loss = -self.loss_function(t_collocation, self.K)[self.K]\n",
    "        grads = loss_tape.gradient(loss, [self.weight])\n",
    "        self.optimizer_dual.apply_gradients(\n",
    "            zip(grads, [self.weight])\n",
    "        )\n",
    "        return -loss\n",
    "\n",
    "\n",
    "    #############################       TRAIN       ############################\n",
    "\n",
    "    def train(self, t_collocation, n_stacked_mf_layers, epochs=1000, t_test=None, u_test=None, u_0=[10.0, 5.0]):\n",
    "        \n",
    "        \"\"\"\n",
    "        initialize the N+1 optimizers\n",
    "        \"\"\"\n",
    "        all_trainable_vars = []\n",
    "        for j in range(self.n_stacked_layers):\n",
    "            _ = self.model(t_collocation, i=j)\n",
    "            _ = self.model.get_alpha_loss(i=j)\n",
    "            if j > 0:\n",
    "                all_trainable_vars.extend(self.model.layers[j-1].trainable_variables)\n",
    "            else:\n",
    "                all_trainable_vars.extend(self.model.first_layer.trainable_variables)\n",
    "            all_trainable_vars.append(self.model.alpha[j])\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                dummy_loss = self.total_loss(t_collocation, j)\n",
    "            dummy_grads = tape.gradient(dummy_loss, all_trainable_vars)\n",
    "            grads_and_vars = [(g, v) for g, v in zip(dummy_grads, all_trainable_vars) if g is not None]\n",
    "            self.optimizer_primal[j].apply_gradients(grads_and_vars)\n",
    "\n",
    "\n",
    "        train_losses, test_losses, l2_errors, gammas, sigma, layer_updated, omegas_t, lambda_phys = ([] for _ in range(8))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            loss = self.primal_update(t_collocation)\n",
    "            if epoch % self.N_dual == 0 and epoch > 0: #dual update\n",
    "                loss = self.dual_update(t_collocation)\n",
    "            if epoch % self.N_resample == 0 and epoch > 0: #resampling of t_collocation\n",
    "                t_collocation = self.resample()\n",
    "\n",
    "            # Learning rate scheduling if type ReduceLROnPlateau\n",
    "            if self.lr_scheduler:\n",
    "                if hasattr(self.lr_scheduler, 'on_epoch_end'):\n",
    "                    self.lr_scheduler.on_epoch_end(epoch=None, logs={\"loss\": loss.numpy()})\n",
    "        \n",
    "            # Logging\n",
    "            if self.logger:\n",
    "                self.logger.log_metrics({\"loss\": loss.numpy()}, step=epoch)\n",
    "\n",
    "            # passing to next stack check\n",
    "            if tf.reduce_mean(self.omegas_t[self.K]).numpy() > self.best_loss:\n",
    "                self.best_loss = tf.reduce_mean(self.omegas_t[self.K]).numpy()\n",
    "                self.bad_epochs = 0\n",
    "            else:\n",
    "                self.bad_epochs += 1\n",
    "\n",
    "            if (self.bad_epochs >= self.patience and self.omegas_t[self.K][-1] > 0.9) or self.bad_epochs >= 2000:\n",
    "                self.best_loss = 0.0\n",
    "                if self.K < self.n_stacked_layers-1 and self.bad_epochs < 1000:\n",
    "                    print(f\"stack {self.K} has converged, passing to the next stack\")\n",
    "                    self.K += 1\n",
    "                    self.bad_epochs = 0\n",
    "                else:\n",
    "                    print(\"all stacks converged, returning to stack 0\")\n",
    "                    if self.epsilon <= 1.0e-1:\n",
    "                        self.epsilon.assign(self.epsilon * 10.0)\n",
    "                    self.K = 0\n",
    "                    self.bad_epochs = 0\n",
    "                    self.update_count += 1\n",
    "                    \n",
    "                    # update u_test to visualize convergence with new gammas\n",
    "                    n_steps = int(5e3)\n",
    "                    u_test = []\n",
    "                    for i in range(n_stacked_mf_layers+1):\n",
    "                        u_t, _ = analytical_solution(n_steps, T_max=self.T_max, parameters_init = self.parameters * self.gammas[i], u_0=u_0)\n",
    "                        u_test.append(u_t)\n",
    "\n",
    "                    # early stopping check\n",
    "                    if tf.reduce_mean(tf.square(self.gammas - self.old_gammas)) > 1.0e-2:\n",
    "                        self.old_gammas = self.gammas\n",
    "                        self.bad_epochs_gamma = 0\n",
    "                    else:\n",
    "                        self.bad_epochs_gamma += 1\n",
    "\n",
    "                    if self.bad_epochs_gamma >= self.patience_gamma:\n",
    "                        print(f\"Early stopping triggered\")\n",
    "                        break\n",
    "             \n",
    "            train_losses.append(loss.numpy())\n",
    "            gammas.append(self.gammas.numpy().copy())\n",
    "            sigma.append(self.sigma.numpy().copy())\n",
    "            layer_updated.append(self.K)\n",
    "            omegas_t.append(self.omegas_t.numpy().copy())\n",
    "            lambda_phys.append(self.weight.numpy().copy())\n",
    "\n",
    "            if epoch % 100 == 0 or epoch == epochs-1:\n",
    "\n",
    "                # Calculate test loss if test data is provided\n",
    "                if t_test is not None and u_test is not None:\n",
    "\n",
    "                    u_pred_test = []\n",
    "                    for i in range(self.model.n_stacked_mf_layers+1):\n",
    "                        u_i, _, _ = self.model(t_test, i)\n",
    "                        u_pred_test.append(u_i)\n",
    "                    test_loss = [tf.reduce_mean(tf.square(u_pred_test_i - u_test_i)).numpy() for u_pred_test_i, u_test_i  in zip(u_pred_test, u_test)]\n",
    "                    test_losses.append(test_loss)\n",
    "\n",
    "                    # Compute L2 relative error\n",
    "                    l2_error = [l2_relative_error(u_pred_test_i, u_test_i) for u_pred_test_i, u_test_i in zip(u_pred_test, u_test)]\n",
    "                    l2_errors.append(l2_error)\n",
    "\n",
    "            \n",
    "                print(f\"Epoch {epoch}, Loss: {loss.numpy():.4e}, L2 Relative_error: {[f'{err:.4f}' for err in l2_error]}, self.gammas: {[f'{gamma:.4f}' for gamma in self.gammas.numpy()]}, epsilon : {self.epsilon.numpy():.1e}, lambda_phys : {self.weight.numpy():.4f}, layer {self.K} is being updated for the {self.update_count}-th time\")\n",
    "\n",
    "        # Plot losses\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_losses, label=\"Training Loss\")\n",
    "        if test_losses:\n",
    "            # test_losses is a list of lists, one per epoch. Plotting the mean test loss across layers.\n",
    "            mean_test_losses = [np.mean(tl) for tl in test_losses]\n",
    "            plt.plot(mean_test_losses, label=\"Test Loss\", color=\"orange\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Test Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(\"losses over epochs.eps\", format='eps')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot L2 relative error over epochs\n",
    "        if l2_errors:  # Check if l2_errors is not empty\n",
    "            plt.figure()\n",
    "            plt.plot(range(len(l2_errors)), l2_errors, label=f\"L2 Relative Error (0-{n_stacked_mf_layers})\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"L2 Relative Error\")\n",
    "            plt.title(\"L2 Relative Error over Training Epochs\")\n",
    "            plt.yscale(\"log\")\n",
    "            plt.legend()\n",
    "            plt.grid(True, which=\"both\")\n",
    "            plt.savefig(\"L2 relative error over epochs.eps\", format='eps')\n",
    "            plt.show()\n",
    "\n",
    "        # plot final output vs analytical solution\n",
    "        t_test = tf.reshape(t_test, [-1]).numpy()\n",
    "        sorted_indices = np.argsort(t_test)\n",
    "        t_sorted = t_test[sorted_indices]\n",
    "        \n",
    "        u_pred_np = u_pred_test[-1].numpy()\n",
    "        u_sorted = u_pred_np[sorted_indices]\n",
    "        u_true_np = u_test[-1].numpy()\n",
    "        u_true_sorted = u_true_np[sorted_indices]\n",
    "\n",
    "        plt.figure(figsize=(10, 20))\n",
    "        plt.subplot(3, 1, 1)\n",
    "        plt.plot(t_sorted, u_sorted, label='x_hat1')\n",
    "        plt.plot(t_sorted, u_true_sorted, label='x1')\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"State\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # Plot gammas over epochs\n",
    "        gammas_np = np.array([alph for alph in gammas])\n",
    "        plt.figure()\n",
    "        for i in range(gammas_np.shape[1]):\n",
    "            plt.plot(range(len(gammas_np)), gammas_np[:, i], label=f\"gamma_{i}\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(f\"gamma values\")\n",
    "        plt.title(\"gamma over Training Epochs\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.savefig(\"gammas over epochs.eps\", format='eps')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot sigmas over epochs\n",
    "        sigma_np = np.array([sigm for sigm in sigma])\n",
    "        plt.figure()\n",
    "        for i in range(sigma_np.shape[1]):\n",
    "            plt.plot(range(len(sigma_np)), sigma_np[:, i], label=f\"sigma_{i}\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(f\"sigma values\")\n",
    "        plt.yscale('symlog', linthresh=1e-3)\n",
    "        plt.title(\"sigma over Training Epochs\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.savefig(\"sigma over epochs.eps\", format='eps')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot k over epochs\n",
    "        plt.figure()\n",
    "        plt.plot(range(len(layer_updated)), layer_updated, label=\"layer_updated\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(f\"layer_updated values\")\n",
    "        plt.title(\"layer_updated over Training Epochs\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.savefig(\"K over epochs.eps\", format='eps')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot lambda_phys over epochs\n",
    "        plt.figure()\n",
    "        plt.plot(range(len(lambda_phys)), lambda_phys, label=\"lambda_phys\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(f\"lambda_phys values\")\n",
    "        plt.title(\"lambda_phys over Training Epochs\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.savefig(\"lambda_phys over epochs.eps\", format='eps')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gammas_init : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 15:29:44.880269: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function StackedResPINN.total_loss at 0x15b2aaca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function StackedResPINN.total_loss at 0x15b2aaca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 0, Loss: 1.0872e-01, L2 Relative_error: ['0.6821', '0.7341', '0.7490', '0.7545', '0.7564', '0.7566', '0.7561', '0.7550', '0.7538', '0.7525'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0000, layer 0 is being updated for the 1-th time\n",
      "Epoch 100, Loss: 9.5405e-02, L2 Relative_error: ['0.0728', '0.2121', '0.2762', '0.3120', '0.3354', '0.3524', '0.3655', '0.3763', '0.3855', '0.3936'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0100, layer 0 is being updated for the 1-th time\n",
      "Epoch 200, Loss: 4.0658e-03, L2 Relative_error: ['0.0048', '0.1580', '0.2225', '0.2589', '0.2830', '0.3006', '0.3144', '0.3257', '0.3354', '0.3439'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0178, layer 0 is being updated for the 1-th time\n",
      "Epoch 300, Loss: 1.3241e-03, L2 Relative_error: ['0.0023', '0.1575', '0.2213', '0.2574', '0.2814', '0.2989', '0.3126', '0.3239', '0.3335', '0.3420'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0214, layer 0 is being updated for the 1-th time\n",
      "Epoch 400, Loss: 9.4849e-04, L2 Relative_error: ['0.0024', '0.1575', '0.2212', '0.2573', '0.2812', '0.2986', '0.3123', '0.3236', '0.3332', '0.3417'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0230, layer 0 is being updated for the 1-th time\n",
      "Epoch 500, Loss: 3.3465e-03, L2 Relative_error: ['0.0111', '0.1571', '0.2218', '0.2585', '0.2828', '0.3006', '0.3146', '0.3262', '0.3361', '0.3448'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0238, layer 0 is being updated for the 1-th time\n",
      "Epoch 600, Loss: 3.3063e-04, L2 Relative_error: ['0.0011', '0.1575', '0.2214', '0.2576', '0.2815', '0.2991', '0.3128', '0.3241', '0.3338', '0.3423'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0242, layer 0 is being updated for the 1-th time\n",
      "Epoch 700, Loss: 2.9107e-04, L2 Relative_error: ['0.0011', '0.1572', '0.2212', '0.2573', '0.2813', '0.2988', '0.3125', '0.3238', '0.3335', '0.3420'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0245, layer 0 is being updated for the 1-th time\n",
      "Epoch 800, Loss: 3.9207e-04, L2 Relative_error: ['0.0027', '0.1574', '0.2215', '0.2577', '0.2817', '0.2993', '0.3131', '0.3244', '0.3341', '0.3427'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0246, layer 0 is being updated for the 1-th time\n",
      "Epoch 900, Loss: 1.8400e-03, L2 Relative_error: ['0.0085', '0.1569', '0.2215', '0.2580', '0.2822', '0.3000', '0.3139', '0.3254', '0.3352', '0.3439'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0248, layer 0 is being updated for the 1-th time\n",
      "Epoch 1000, Loss: 1.6102e-04, L2 Relative_error: ['0.0012', '0.1573', '0.2212', '0.2572', '0.2811', '0.2986', '0.3123', '0.3235', '0.3332', '0.3416'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0249, layer 0 is being updated for the 1-th time\n",
      "Epoch 1100, Loss: 1.7984e-03, L2 Relative_error: ['0.0084', '0.1572', '0.2217', '0.2582', '0.2824', '0.3001', '0.3141', '0.3256', '0.3354', '0.3440'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0251, layer 0 is being updated for the 1-th time\n",
      "stack 0 has converged, passing to the next stack\n",
      "Epoch 1200, Loss: 1.3929e-04, L2 Relative_error: ['0.0011', '0.1563', '0.2192', '0.2547', '0.2781', '0.2953', '0.3087', '0.3197', '0.3291', '0.3373'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0252, layer 1 is being updated for the 1-th time\n",
      "Epoch 1300, Loss: 1.3661e-04, L2 Relative_error: ['0.0011', '0.1540', '0.2153', '0.2501', '0.2731', '0.2898', '0.3029', '0.3135', '0.3226', '0.3306'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0252, layer 1 is being updated for the 1-th time\n",
      "Epoch 1400, Loss: 1.3875e-04, L2 Relative_error: ['0.0011', '0.1432', '0.2070', '0.2432', '0.2671', '0.2845', '0.2981', '0.3092', '0.3187', '0.3271'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0253, layer 1 is being updated for the 1-th time\n",
      "Epoch 1500, Loss: 1.3767e-04, L2 Relative_error: ['0.0011', '0.1198', '0.1864', '0.2246', '0.2499', '0.2683', '0.2827', '0.2946', '0.3046', '0.3134'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0253, layer 1 is being updated for the 1-th time\n",
      "Epoch 1600, Loss: 1.3835e-04, L2 Relative_error: ['0.0011', '0.1083', '0.1759', '0.2157', '0.2422', '0.2617', '0.2769', '0.2894', '0.3001', '0.3094'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0254, layer 1 is being updated for the 1-th time\n",
      "Epoch 1700, Loss: 9.3859e-05, L2 Relative_error: ['0.0011', '0.1006', '0.1678', '0.2076', '0.2341', '0.2535', '0.2687', '0.2811', '0.2917', '0.3010'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0254, layer 1 is being updated for the 1-th time\n",
      "Epoch 1800, Loss: 1.2809e-04, L2 Relative_error: ['0.0011', '0.0874', '0.1558', '0.1964', '0.2236', '0.2434', '0.2590', '0.2717', '0.2826', '0.2921'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0255, layer 1 is being updated for the 1-th time\n",
      "Epoch 1900, Loss: 1.4864e-04, L2 Relative_error: ['0.0011', '0.0655', '0.1343', '0.1763', '0.2046', '0.2253', '0.2416', '0.2550', '0.2663', '0.2763'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0255, layer 1 is being updated for the 1-th time\n",
      "Epoch 2000, Loss: 1.6732e-04, L2 Relative_error: ['0.0011', '0.0452', '0.1148', '0.1578', '0.1869', '0.2084', '0.2253', '0.2392', '0.2510', '0.2613'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0256, layer 1 is being updated for the 1-th time\n",
      "Epoch 2100, Loss: 1.3502e-04, L2 Relative_error: ['0.0011', '0.0292', '0.0986', '0.1421', '0.1718', '0.1937', '0.2110', '0.2253', '0.2374', '0.2481'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0257, layer 1 is being updated for the 1-th time\n",
      "Epoch 2200, Loss: 1.5424e-04, L2 Relative_error: ['0.0011', '0.0202', '0.0899', '0.1335', '0.1632', '0.1853', '0.2027', '0.2171', '0.2294', '0.2402'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0257, layer 1 is being updated for the 1-th time\n",
      "Epoch 2300, Loss: 1.3619e-04, L2 Relative_error: ['0.0011', '0.0147', '0.0846', '0.1282', '0.1579', '0.1800', '0.1976', '0.2120', '0.2244', '0.2353'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0258, layer 1 is being updated for the 1-th time\n",
      "Epoch 2400, Loss: 1.3303e-04, L2 Relative_error: ['0.0011', '0.0112', '0.0821', '0.1257', '0.1554', '0.1775', '0.1950', '0.2095', '0.2219', '0.2329'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0258, layer 1 is being updated for the 1-th time\n",
      "Epoch 2500, Loss: 1.2868e-04, L2 Relative_error: ['0.0011', '0.0085', '0.0801', '0.1236', '0.1533', '0.1755', '0.1930', '0.2076', '0.2200', '0.2309'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0259, layer 1 is being updated for the 1-th time\n",
      "Epoch 2600, Loss: 1.4665e-04, L2 Relative_error: ['0.0011', '0.0056', '0.0771', '0.1208', '0.1505', '0.1727', '0.1903', '0.2050', '0.2175', '0.2285'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0260, layer 1 is being updated for the 1-th time\n",
      "Epoch 2700, Loss: 1.3979e-04, L2 Relative_error: ['0.0011', '0.0044', '0.0766', '0.1202', '0.1500', '0.1721', '0.1898', '0.2044', '0.2169', '0.2279'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0260, layer 1 is being updated for the 1-th time\n",
      "Epoch 2800, Loss: 1.7355e-04, L2 Relative_error: ['0.0011', '0.0033', '0.0754', '0.1189', '0.1487', '0.1708', '0.1884', '0.2030', '0.2156', '0.2266'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0261, layer 1 is being updated for the 1-th time\n",
      "Epoch 2900, Loss: 1.4960e-04, L2 Relative_error: ['0.0011', '0.0028', '0.0750', '0.1185', '0.1483', '0.1704', '0.1880', '0.2026', '0.2152', '0.2262'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0262, layer 1 is being updated for the 1-th time\n",
      "stack 1 has converged, passing to the next stack\n",
      "Epoch 3000, Loss: 1.6565e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0722', '0.1147', '0.1438', '0.1655', '0.1827', '0.1969', '0.2091', '0.2198'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0263, layer 2 is being updated for the 1-th time\n",
      "Epoch 3100, Loss: 1.4745e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0709', '0.1123', '0.1408', '0.1622', '0.1791', '0.1930', '0.2050', '0.2155'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0263, layer 2 is being updated for the 1-th time\n",
      "Epoch 3200, Loss: 1.0478e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0691', '0.1105', '0.1392', '0.1606', '0.1775', '0.1916', '0.2036', '0.2141'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0264, layer 2 is being updated for the 1-th time\n",
      "Epoch 3300, Loss: 1.2501e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0655', '0.1074', '0.1364', '0.1581', '0.1753', '0.1895', '0.2017', '0.2124'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0265, layer 2 is being updated for the 1-th time\n",
      "Epoch 3400, Loss: 1.4096e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0635', '0.1051', '0.1343', '0.1562', '0.1736', '0.1879', '0.2002', '0.2110'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0266, layer 2 is being updated for the 1-th time\n",
      "Epoch 3500, Loss: 1.3558e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0623', '0.1035', '0.1328', '0.1547', '0.1721', '0.1866', '0.1989', '0.2097'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0266, layer 2 is being updated for the 1-th time\n",
      "Epoch 3600, Loss: 1.5382e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0593', '0.1012', '0.1308', '0.1530', '0.1706', '0.1852', '0.1976', '0.2086'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0267, layer 2 is being updated for the 1-th time\n",
      "Epoch 3700, Loss: 1.3519e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0533', '0.0952', '0.1251', '0.1475', '0.1652', '0.1799', '0.1925', '0.2035'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0268, layer 2 is being updated for the 1-th time\n",
      "Epoch 3800, Loss: 1.4286e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0447', '0.0868', '0.1171', '0.1399', '0.1579', '0.1729', '0.1857', '0.1969'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0269, layer 2 is being updated for the 1-th time\n",
      "Epoch 3900, Loss: 1.5192e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0345', '0.0754', '0.1062', '0.1295', '0.1481', '0.1635', '0.1766', '0.1882'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0270, layer 2 is being updated for the 1-th time\n",
      "Epoch 4000, Loss: 1.5210e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0266', '0.0675', '0.0986', '0.1221', '0.1409', '0.1565', '0.1699', '0.1816'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0271, layer 2 is being updated for the 1-th time\n",
      "Epoch 4100, Loss: 1.7302e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0203', '0.0617', '0.0931', '0.1169', '0.1360', '0.1518', '0.1653', '0.1772'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0271, layer 2 is being updated for the 1-th time\n",
      "Epoch 4200, Loss: 1.2266e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0153', '0.0572', '0.0887', '0.1126', '0.1316', '0.1475', '0.1612', '0.1732'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0272, layer 2 is being updated for the 1-th time\n",
      "Epoch 4300, Loss: 1.2652e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0112', '0.0533', '0.0849', '0.1089', '0.1281', '0.1441', '0.1578', '0.1699'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0273, layer 2 is being updated for the 1-th time\n",
      "Epoch 4400, Loss: 1.2946e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0087', '0.0509', '0.0826', '0.1066', '0.1258', '0.1418', '0.1556', '0.1677'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0274, layer 2 is being updated for the 1-th time\n",
      "Epoch 4500, Loss: 1.4438e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0076', '0.0506', '0.0823', '0.1062', '0.1254', '0.1414', '0.1552', '0.1673'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0275, layer 2 is being updated for the 1-th time\n",
      "Epoch 4600, Loss: 1.2536e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0068', '0.0500', '0.0817', '0.1057', '0.1249', '0.1409', '0.1547', '0.1668'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0276, layer 2 is being updated for the 1-th time\n",
      "Epoch 4700, Loss: 1.6817e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0058', '0.0489', '0.0806', '0.1046', '0.1238', '0.1398', '0.1536', '0.1657'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0277, layer 2 is being updated for the 1-th time\n",
      "Epoch 4800, Loss: 1.1428e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0056', '0.0490', '0.0807', '0.1047', '0.1239', '0.1399', '0.1537', '0.1658'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0278, layer 2 is being updated for the 1-th time\n",
      "Epoch 4900, Loss: 1.4137e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0050', '0.0485', '0.0802', '0.1042', '0.1234', '0.1394', '0.1532', '0.1653'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0279, layer 2 is being updated for the 1-th time\n",
      "Epoch 5000, Loss: 1.4960e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0043', '0.0477', '0.0794', '0.1034', '0.1226', '0.1386', '0.1524', '0.1646'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0280, layer 2 is being updated for the 1-th time\n",
      "Epoch 5100, Loss: 1.2105e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0044', '0.0482', '0.0799', '0.1039', '0.1231', '0.1391', '0.1528', '0.1650'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0281, layer 2 is being updated for the 1-th time\n",
      "Epoch 5200, Loss: 1.2730e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0041', '0.0480', '0.0797', '0.1036', '0.1228', '0.1388', '0.1526', '0.1647'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0282, layer 2 is being updated for the 1-th time\n",
      "Epoch 5300, Loss: 1.2835e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0037', '0.0477', '0.0794', '0.1034', '0.1226', '0.1386', '0.1524', '0.1645'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0283, layer 2 is being updated for the 1-th time\n",
      "stack 2 has converged, passing to the next stack\n",
      "Epoch 5400, Loss: 1.4472e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0474', '0.0791', '0.1031', '0.1222', '0.1382', '0.1520', '0.1642'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0284, layer 3 is being updated for the 1-th time\n",
      "Epoch 5500, Loss: 1.2066e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0438', '0.0733', '0.0962', '0.1147', '0.1301', '0.1433', '0.1550'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0285, layer 3 is being updated for the 1-th time\n",
      "Epoch 5600, Loss: 1.3175e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0436', '0.0730', '0.0958', '0.1142', '0.1296', '0.1428', '0.1545'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0286, layer 3 is being updated for the 1-th time\n",
      "Epoch 5700, Loss: 1.4486e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0432', '0.0727', '0.0957', '0.1141', '0.1295', '0.1428', '0.1545'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0287, layer 3 is being updated for the 1-th time\n",
      "Epoch 5800, Loss: 1.2079e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0427', '0.0722', '0.0951', '0.1136', '0.1290', '0.1423', '0.1540'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0288, layer 3 is being updated for the 1-th time\n",
      "Epoch 5900, Loss: 1.5740e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0420', '0.0714', '0.0944', '0.1129', '0.1284', '0.1417', '0.1535'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0289, layer 3 is being updated for the 1-th time\n",
      "Epoch 6000, Loss: 1.4104e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0417', '0.0713', '0.0944', '0.1130', '0.1285', '0.1419', '0.1537'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0290, layer 3 is being updated for the 1-th time\n",
      "Epoch 6100, Loss: 1.2870e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0414', '0.0710', '0.0941', '0.1128', '0.1283', '0.1417', '0.1536'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0291, layer 3 is being updated for the 1-th time\n",
      "Epoch 6200, Loss: 1.4992e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0409', '0.0704', '0.0935', '0.1121', '0.1277', '0.1410', '0.1528'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0292, layer 3 is being updated for the 1-th time\n",
      "Epoch 6300, Loss: 1.3480e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0399', '0.0691', '0.0923', '0.1110', '0.1266', '0.1401', '0.1520'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0294, layer 3 is being updated for the 1-th time\n",
      "Epoch 6400, Loss: 1.4989e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0376', '0.0669', '0.0901', '0.1089', '0.1246', '0.1381', '0.1500'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0295, layer 3 is being updated for the 1-th time\n",
      "Epoch 6500, Loss: 1.3445e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0340', '0.0631', '0.0866', '0.1056', '0.1214', '0.1351', '0.1471'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0296, layer 3 is being updated for the 1-th time\n",
      "Epoch 6600, Loss: 1.4279e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0306', '0.0593', '0.0829', '0.1020', '0.1180', '0.1318', '0.1440'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0297, layer 3 is being updated for the 1-th time\n",
      "Epoch 6700, Loss: 1.5500e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0262', '0.0549', '0.0787', '0.0981', '0.1143', '0.1283', '0.1406'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0298, layer 3 is being updated for the 1-th time\n",
      "Epoch 6800, Loss: 1.2194e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0216', '0.0502', '0.0742', '0.0938', '0.1102', '0.1244', '0.1368'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0300, layer 3 is being updated for the 1-th time\n",
      "Epoch 6900, Loss: 1.2698e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0175', '0.0464', '0.0707', '0.0905', '0.1070', '0.1213', '0.1339'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0301, layer 3 is being updated for the 1-th time\n",
      "Epoch 7000, Loss: 1.3509e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0139', '0.0430', '0.0674', '0.0873', '0.1039', '0.1183', '0.1310'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0302, layer 3 is being updated for the 1-th time\n",
      "Epoch 7100, Loss: 1.3369e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0117', '0.0411', '0.0656', '0.0855', '0.1022', '0.1166', '0.1293'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0303, layer 3 is being updated for the 1-th time\n",
      "Epoch 7200, Loss: 1.1280e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0105', '0.0401', '0.0646', '0.0845', '0.1012', '0.1156', '0.1284'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0304, layer 3 is being updated for the 1-th time\n",
      "Epoch 7300, Loss: 1.4183e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0093', '0.0389', '0.0635', '0.0834', '0.1001', '0.1145', '0.1273'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0306, layer 3 is being updated for the 1-th time\n",
      "Epoch 7400, Loss: 1.6095e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0083', '0.0378', '0.0624', '0.0823', '0.0991', '0.1135', '0.1263'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0307, layer 3 is being updated for the 1-th time\n",
      "Epoch 7500, Loss: 1.1467e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0078', '0.0377', '0.0623', '0.0822', '0.0989', '0.1133', '0.1261'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0308, layer 3 is being updated for the 1-th time\n",
      "Epoch 7600, Loss: 1.1540e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0073', '0.0372', '0.0618', '0.0817', '0.0985', '0.1129', '0.1257'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0310, layer 3 is being updated for the 1-th time\n",
      "Epoch 7700, Loss: 1.3884e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0065', '0.0361', '0.0608', '0.0807', '0.0975', '0.1120', '0.1247'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0311, layer 3 is being updated for the 1-th time\n",
      "Epoch 7800, Loss: 1.6229e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0060', '0.0358', '0.0605', '0.0804', '0.0972', '0.1117', '0.1244'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0312, layer 3 is being updated for the 1-th time\n",
      "Epoch 7900, Loss: 1.5771e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0055', '0.0354', '0.0601', '0.0800', '0.0968', '0.1112', '0.1240'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0314, layer 3 is being updated for the 1-th time\n",
      "Epoch 8000, Loss: 1.4440e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0054', '0.0356', '0.0603', '0.0803', '0.0970', '0.1115', '0.1243'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0315, layer 3 is being updated for the 1-th time\n",
      "Epoch 8100, Loss: 1.8290e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0048', '0.0349', '0.0596', '0.0795', '0.0963', '0.1108', '0.1236'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0317, layer 3 is being updated for the 1-th time\n",
      "Epoch 8200, Loss: 1.4461e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0048', '0.0352', '0.0599', '0.0798', '0.0966', '0.1110', '0.1238'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0318, layer 3 is being updated for the 1-th time\n",
      "stack 3 has converged, passing to the next stack\n",
      "Epoch 8300, Loss: 1.0928e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0319', '0.0547', '0.0738', '0.0900', '0.1040', '0.1164'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0320, layer 4 is being updated for the 1-th time\n",
      "Epoch 8400, Loss: 1.5371e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0317', '0.0541', '0.0730', '0.0891', '0.1030', '0.1153'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0321, layer 4 is being updated for the 1-th time\n",
      "Epoch 8500, Loss: 1.1626e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0316', '0.0541', '0.0730', '0.0891', '0.1030', '0.1153'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0322, layer 4 is being updated for the 1-th time\n",
      "Epoch 8600, Loss: 1.3766e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0315', '0.0540', '0.0729', '0.0890', '0.1029', '0.1153'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0324, layer 4 is being updated for the 1-th time\n",
      "Epoch 8700, Loss: 1.5289e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0313', '0.0538', '0.0727', '0.0888', '0.1028', '0.1151'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0325, layer 4 is being updated for the 1-th time\n",
      "Epoch 8800, Loss: 1.4528e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0311', '0.0537', '0.0727', '0.0888', '0.1028', '0.1151'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0326, layer 4 is being updated for the 1-th time\n",
      "Epoch 8900, Loss: 1.2239e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0311', '0.0535', '0.0725', '0.0886', '0.1026', '0.1150'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0328, layer 4 is being updated for the 1-th time\n",
      "Epoch 9000, Loss: 1.4130e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0310', '0.0535', '0.0725', '0.0886', '0.1026', '0.1149'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0329, layer 4 is being updated for the 1-th time\n",
      "Epoch 9100, Loss: 1.6223e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0309', '0.0533', '0.0723', '0.0884', '0.1024', '0.1148'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0331, layer 4 is being updated for the 1-th time\n",
      "Epoch 9200, Loss: 1.4454e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0309', '0.0534', '0.0724', '0.0885', '0.1025', '0.1149'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0332, layer 4 is being updated for the 1-th time\n",
      "Epoch 9300, Loss: 1.3418e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0307', '0.0531', '0.0721', '0.0882', '0.1022', '0.1146'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0334, layer 4 is being updated for the 1-th time\n",
      "Epoch 9400, Loss: 1.4192e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0303', '0.0528', '0.0718', '0.0879', '0.1019', '0.1144'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0335, layer 4 is being updated for the 1-th time\n",
      "Epoch 9500, Loss: 1.5719e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0295', '0.0518', '0.0709', '0.0871', '0.1012', '0.1136'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0337, layer 4 is being updated for the 1-th time\n",
      "Epoch 9600, Loss: 1.4650e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0280', '0.0501', '0.0691', '0.0854', '0.0995', '0.1120'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0339, layer 4 is being updated for the 1-th time\n",
      "Epoch 9700, Loss: 1.2459e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0265', '0.0484', '0.0676', '0.0839', '0.0980', '0.1106'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0340, layer 4 is being updated for the 1-th time\n",
      "Epoch 9800, Loss: 1.3234e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0248', '0.0467', '0.0660', '0.0824', '0.0967', '0.1093'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0342, layer 4 is being updated for the 1-th time\n",
      "Epoch 9900, Loss: 1.5714e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0223', '0.0443', '0.0637', '0.0803', '0.0947', '0.1074'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0343, layer 4 is being updated for the 1-th time\n",
      "Epoch 10000, Loss: 1.6078e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0197', '0.0411', '0.0606', '0.0773', '0.0919', '0.1047'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0345, layer 4 is being updated for the 1-th time\n",
      "Epoch 10100, Loss: 1.5606e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0174', '0.0391', '0.0588', '0.0756', '0.0903', '0.1032'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0347, layer 4 is being updated for the 1-th time\n",
      "Epoch 10200, Loss: 1.6151e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0153', '0.0369', '0.0567', '0.0736', '0.0883', '0.1013'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0348, layer 4 is being updated for the 1-th time\n",
      "Epoch 10300, Loss: 1.3993e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0136', '0.0353', '0.0551', '0.0721', '0.0869', '0.0999'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0350, layer 4 is being updated for the 1-th time\n",
      "Epoch 10400, Loss: 1.3226e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0124', '0.0345', '0.0544', '0.0714', '0.0862', '0.0992'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0352, layer 4 is being updated for the 1-th time\n",
      "Epoch 10500, Loss: 1.3838e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0114', '0.0334', '0.0534', '0.0704', '0.0851', '0.0982'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0353, layer 4 is being updated for the 1-th time\n",
      "Epoch 10600, Loss: 1.3245e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0104', '0.0324', '0.0524', '0.0695', '0.0843', '0.0974'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0355, layer 4 is being updated for the 1-th time\n",
      "Epoch 10700, Loss: 1.6918e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0097', '0.0316', '0.0517', '0.0687', '0.0835', '0.0967'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0357, layer 4 is being updated for the 1-th time\n",
      "Epoch 10800, Loss: 1.4233e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0089', '0.0309', '0.0510', '0.0681', '0.0829', '0.0960'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0359, layer 4 is being updated for the 1-th time\n",
      "Epoch 10900, Loss: 1.5361e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0086', '0.0309', '0.0509', '0.0680', '0.0828', '0.0960'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0360, layer 4 is being updated for the 1-th time\n",
      "Epoch 11000, Loss: 1.5867e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0083', '0.0306', '0.0507', '0.0677', '0.0826', '0.0957'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0362, layer 4 is being updated for the 1-th time\n",
      "Epoch 11100, Loss: 1.5588e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0080', '0.0305', '0.0506', '0.0676', '0.0825', '0.0956'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0364, layer 4 is being updated for the 1-th time\n",
      "Epoch 11200, Loss: 1.6070e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0077', '0.0300', '0.0501', '0.0672', '0.0820', '0.0952'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0366, layer 4 is being updated for the 1-th time\n",
      "Epoch 11300, Loss: 1.4959e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0076', '0.0301', '0.0503', '0.0673', '0.0822', '0.0953'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0368, layer 4 is being updated for the 1-th time\n",
      "Epoch 11400, Loss: 1.3385e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0074', '0.0299', '0.0501', '0.0672', '0.0820', '0.0951'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0369, layer 4 is being updated for the 1-th time\n",
      "Epoch 11500, Loss: 1.6998e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0069', '0.0292', '0.0494', '0.0665', '0.0814', '0.0945'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0371, layer 4 is being updated for the 1-th time\n",
      "Epoch 11600, Loss: 1.4371e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0068', '0.0294', '0.0496', '0.0667', '0.0815', '0.0947'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0373, layer 4 is being updated for the 1-th time\n",
      "Epoch 11700, Loss: 1.3062e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0068', '0.0294', '0.0496', '0.0667', '0.0815', '0.0946'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0375, layer 4 is being updated for the 1-th time\n",
      "Epoch 11800, Loss: 1.6665e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0062', '0.0288', '0.0490', '0.0661', '0.0810', '0.0941'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0377, layer 4 is being updated for the 1-th time\n",
      "stack 4 has converged, passing to the next stack\n",
      "Epoch 11900, Loss: 1.2356e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0252', '0.0434', '0.0596', '0.0739', '0.0867'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0379, layer 5 is being updated for the 1-th time\n",
      "Epoch 12000, Loss: 1.2571e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0251', '0.0430', '0.0591', '0.0733', '0.0860'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0381, layer 5 is being updated for the 1-th time\n",
      "Epoch 12100, Loss: 1.4612e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0250', '0.0429', '0.0591', '0.0733', '0.0860'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0383, layer 5 is being updated for the 1-th time\n",
      "Epoch 12200, Loss: 1.6681e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0250', '0.0429', '0.0590', '0.0732', '0.0859'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0385, layer 5 is being updated for the 1-th time\n",
      "Epoch 12300, Loss: 1.5403e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0249', '0.0428', '0.0589', '0.0732', '0.0859'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0387, layer 5 is being updated for the 1-th time\n",
      "Epoch 12400, Loss: 1.4371e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0249', '0.0428', '0.0589', '0.0732', '0.0859'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0389, layer 5 is being updated for the 1-th time\n",
      "Epoch 12500, Loss: 1.4559e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0249', '0.0428', '0.0589', '0.0732', '0.0859'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0391, layer 5 is being updated for the 1-th time\n",
      "Epoch 12600, Loss: 1.1783e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0248', '0.0428', '0.0589', '0.0732', '0.0859'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0393, layer 5 is being updated for the 1-th time\n",
      "Epoch 12700, Loss: 1.3165e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0248', '0.0427', '0.0589', '0.0732', '0.0859'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0395, layer 5 is being updated for the 1-th time\n",
      "Epoch 12800, Loss: 1.5695e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0248', '0.0427', '0.0589', '0.0731', '0.0859'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0397, layer 5 is being updated for the 1-th time\n",
      "Epoch 12900, Loss: 1.8618e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0247', '0.0426', '0.0587', '0.0730', '0.0857'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0399, layer 5 is being updated for the 1-th time\n",
      "Epoch 13000, Loss: 1.6025e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0246', '0.0424', '0.0585', '0.0728', '0.0855'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0401, layer 5 is being updated for the 1-th time\n",
      "Epoch 13100, Loss: 1.4042e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0244', '0.0422', '0.0583', '0.0726', '0.0853'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0403, layer 5 is being updated for the 1-th time\n",
      "Epoch 13200, Loss: 1.3304e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0239', '0.0417', '0.0578', '0.0721', '0.0849'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0405, layer 5 is being updated for the 1-th time\n",
      "Epoch 13300, Loss: 1.5061e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0232', '0.0408', '0.0570', '0.0713', '0.0841'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0407, layer 5 is being updated for the 1-th time\n",
      "Epoch 13400, Loss: 1.6346e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0225', '0.0398', '0.0560', '0.0704', '0.0832'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0409, layer 5 is being updated for the 1-th time\n",
      "Epoch 13500, Loss: 1.2484e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0214', '0.0388', '0.0551', '0.0695', '0.0824'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0411, layer 5 is being updated for the 1-th time\n",
      "Epoch 13600, Loss: 1.3694e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0200', '0.0370', '0.0533', '0.0679', '0.0808'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0413, layer 5 is being updated for the 1-th time\n",
      "Epoch 13700, Loss: 1.3412e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0184', '0.0355', '0.0519', '0.0665', '0.0796'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0415, layer 5 is being updated for the 1-th time\n",
      "Epoch 13800, Loss: 1.6329e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0169', '0.0339', '0.0504', '0.0651', '0.0782'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0417, layer 5 is being updated for the 1-th time\n",
      "Epoch 13900, Loss: 1.2571e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0155', '0.0328', '0.0494', '0.0641', '0.0773'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0420, layer 5 is being updated for the 1-th time\n",
      "Epoch 14000, Loss: 1.7019e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0143', '0.0311', '0.0477', '0.0625', '0.0758'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0422, layer 5 is being updated for the 1-th time\n",
      "Epoch 14100, Loss: 1.3991e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0133', '0.0304', '0.0472', '0.0620', '0.0752'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0424, layer 5 is being updated for the 1-th time\n",
      "Epoch 14200, Loss: 1.3005e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0124', '0.0295', '0.0463', '0.0611', '0.0744'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0426, layer 5 is being updated for the 1-th time\n",
      "Epoch 14300, Loss: 1.5666e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0117', '0.0288', '0.0456', '0.0605', '0.0738'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0428, layer 5 is being updated for the 1-th time\n",
      "Epoch 14400, Loss: 1.2958e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0110', '0.0280', '0.0449', '0.0598', '0.0731'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0430, layer 5 is being updated for the 1-th time\n",
      "Epoch 14500, Loss: 1.3705e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0107', '0.0280', '0.0449', '0.0598', '0.0731'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0433, layer 5 is being updated for the 1-th time\n",
      "Epoch 14600, Loss: 1.5665e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0101', '0.0274', '0.0443', '0.0592', '0.0725'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0435, layer 5 is being updated for the 1-th time\n",
      "Epoch 14700, Loss: 1.2927e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0098', '0.0271', '0.0440', '0.0589', '0.0723'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0437, layer 5 is being updated for the 1-th time\n",
      "Epoch 14800, Loss: 1.6415e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0092', '0.0264', '0.0434', '0.0583', '0.0717'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0440, layer 5 is being updated for the 1-th time\n",
      "Epoch 14900, Loss: 1.2095e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0093', '0.0268', '0.0437', '0.0587', '0.0720'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0442, layer 5 is being updated for the 1-th time\n",
      "Epoch 15000, Loss: 1.3463e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0089', '0.0263', '0.0433', '0.0582', '0.0716'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0445, layer 5 is being updated for the 1-th time\n",
      "Epoch 15100, Loss: 1.5123e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0086', '0.0263', '0.0434', '0.0584', '0.0717'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0447, layer 5 is being updated for the 1-th time\n",
      "Epoch 15200, Loss: 1.6620e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0084', '0.0258', '0.0428', '0.0578', '0.0712'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0449, layer 5 is being updated for the 1-th time\n",
      "Epoch 15300, Loss: 1.5077e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0083', '0.0259', '0.0429', '0.0579', '0.0712'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0452, layer 5 is being updated for the 1-th time\n",
      "Epoch 15400, Loss: 1.3509e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0081', '0.0256', '0.0427', '0.0576', '0.0710'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0454, layer 5 is being updated for the 1-th time\n",
      "Epoch 15500, Loss: 1.5047e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0079', '0.0254', '0.0425', '0.0575', '0.0708'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0457, layer 5 is being updated for the 1-th time\n",
      "Epoch 15600, Loss: 1.3533e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0078', '0.0255', '0.0425', '0.0575', '0.0709'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0459, layer 5 is being updated for the 1-th time\n",
      "Epoch 15700, Loss: 1.5081e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0077', '0.0253', '0.0423', '0.0573', '0.0707'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0462, layer 5 is being updated for the 1-th time\n",
      "Epoch 15800, Loss: 1.3704e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0075', '0.0251', '0.0422', '0.0572', '0.0705'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0464, layer 5 is being updated for the 1-th time\n",
      "Epoch 15900, Loss: 1.3315e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0077', '0.0254', '0.0425', '0.0575', '0.0709'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0467, layer 5 is being updated for the 1-th time\n",
      "Epoch 16000, Loss: 1.7926e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0074', '0.0250', '0.0420', '0.0571', '0.0704'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0469, layer 5 is being updated for the 1-th time\n",
      "Epoch 16100, Loss: 1.3282e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0075', '0.0252', '0.0422', '0.0573', '0.0706'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0472, layer 5 is being updated for the 1-th time\n",
      "Epoch 16200, Loss: 1.1770e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0074', '0.0250', '0.0421', '0.0571', '0.0705'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0474, layer 5 is being updated for the 1-th time\n",
      "Epoch 16300, Loss: 1.6796e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0072', '0.0247', '0.0418', '0.0568', '0.0702'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0477, layer 5 is being updated for the 1-th time\n",
      "Epoch 16400, Loss: 1.4136e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0072', '0.0249', '0.0420', '0.0570', '0.0704'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0479, layer 5 is being updated for the 1-th time\n",
      "Epoch 16500, Loss: 1.3389e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0072', '0.0249', '0.0420', '0.0570', '0.0704'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0482, layer 5 is being updated for the 1-th time\n",
      "Epoch 16600, Loss: 1.4730e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0072', '0.0250', '0.0420', '0.0571', '0.0704'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0484, layer 5 is being updated for the 1-th time\n",
      "Epoch 16700, Loss: 1.5227e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0072', '0.0248', '0.0419', '0.0569', '0.0703'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0487, layer 5 is being updated for the 1-th time\n",
      "Epoch 16800, Loss: 1.5599e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0071', '0.0248', '0.0419', '0.0570', '0.0703'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0490, layer 5 is being updated for the 1-th time\n",
      "Epoch 16900, Loss: 1.4240e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0071', '0.0250', '0.0421', '0.0571', '0.0704'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0492, layer 5 is being updated for the 1-th time\n",
      "Epoch 17000, Loss: 1.3558e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0071', '0.0249', '0.0420', '0.0571', '0.0704'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0495, layer 5 is being updated for the 1-th time\n",
      "Epoch 17100, Loss: 2.0437e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0241', '0.0413', '0.0563', '0.0697'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0498, layer 5 is being updated for the 1-th time\n",
      "stack 5 has converged, passing to the next stack\n",
      "Epoch 17200, Loss: 1.4068e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0208', '0.0355', '0.0496', '0.0624'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0501, layer 6 is being updated for the 1-th time\n",
      "Epoch 17300, Loss: 1.4254e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0207', '0.0355', '0.0496', '0.0624'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0503, layer 6 is being updated for the 1-th time\n",
      "Epoch 17400, Loss: 1.5187e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0207', '0.0355', '0.0496', '0.0624'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0506, layer 6 is being updated for the 1-th time\n",
      "Epoch 17500, Loss: 1.3794e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0207', '0.0355', '0.0496', '0.0624'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0509, layer 6 is being updated for the 1-th time\n",
      "Epoch 17600, Loss: 1.3994e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0206', '0.0354', '0.0495', '0.0623'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0511, layer 6 is being updated for the 1-th time\n",
      "Epoch 17700, Loss: 1.3053e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0206', '0.0354', '0.0495', '0.0624'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0514, layer 6 is being updated for the 1-th time\n",
      "Epoch 17800, Loss: 1.6483e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0206', '0.0353', '0.0494', '0.0622'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0517, layer 6 is being updated for the 1-th time\n",
      "Epoch 17900, Loss: 1.5504e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0206', '0.0354', '0.0495', '0.0623'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0520, layer 6 is being updated for the 1-th time\n",
      "Epoch 18000, Loss: 1.4955e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0206', '0.0354', '0.0495', '0.0623'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0523, layer 6 is being updated for the 1-th time\n",
      "Epoch 18100, Loss: 1.5039e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0206', '0.0354', '0.0495', '0.0623'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0525, layer 6 is being updated for the 1-th time\n",
      "Epoch 18200, Loss: 1.8785e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0206', '0.0353', '0.0494', '0.0623'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0528, layer 6 is being updated for the 1-th time\n",
      "Epoch 18300, Loss: 1.4201e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0205', '0.0353', '0.0494', '0.0622'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0531, layer 6 is being updated for the 1-th time\n",
      "Epoch 18400, Loss: 1.8501e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0204', '0.0352', '0.0493', '0.0621'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0534, layer 6 is being updated for the 1-th time\n",
      "Epoch 18500, Loss: 1.5006e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0203', '0.0350', '0.0491', '0.0619'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0537, layer 6 is being updated for the 1-th time\n",
      "Epoch 18600, Loss: 1.4406e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0201', '0.0348', '0.0489', '0.0617'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0540, layer 6 is being updated for the 1-th time\n",
      "Epoch 18700, Loss: 1.4894e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0198', '0.0343', '0.0483', '0.0612'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0543, layer 6 is being updated for the 1-th time\n",
      "Epoch 18800, Loss: 1.3817e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0195', '0.0340', '0.0481', '0.0609'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0546, layer 6 is being updated for the 1-th time\n",
      "Epoch 18900, Loss: 1.5089e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0192', '0.0336', '0.0477', '0.0606'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0549, layer 6 is being updated for the 1-th time\n",
      "Epoch 19000, Loss: 1.3537e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0185', '0.0328', '0.0469', '0.0599'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0552, layer 6 is being updated for the 1-th time\n",
      "Epoch 19100, Loss: 1.4293e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0176', '0.0319', '0.0462', '0.0591'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0555, layer 6 is being updated for the 1-th time\n",
      "Epoch 19200, Loss: 1.4482e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0169', '0.0312', '0.0454', '0.0584'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0558, layer 6 is being updated for the 1-th time\n",
      "Epoch 19300, Loss: 1.6308e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0161', '0.0303', '0.0446', '0.0577'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0562, layer 6 is being updated for the 1-th time\n",
      "Epoch 19400, Loss: 1.3575e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0153', '0.0292', '0.0435', '0.0566'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0565, layer 6 is being updated for the 1-th time\n",
      "Epoch 19500, Loss: 1.3637e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0144', '0.0282', '0.0425', '0.0556'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0568, layer 6 is being updated for the 1-th time\n",
      "Epoch 19600, Loss: 1.5075e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0135', '0.0273', '0.0417', '0.0549'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0571, layer 6 is being updated for the 1-th time\n",
      "Epoch 19700, Loss: 1.2732e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0128', '0.0269', '0.0413', '0.0546'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0574, layer 6 is being updated for the 1-th time\n",
      "Epoch 19800, Loss: 1.6683e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0122', '0.0262', '0.0407', '0.0540'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0577, layer 6 is being updated for the 1-th time\n",
      "Epoch 19900, Loss: 1.5676e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0117', '0.0258', '0.0403', '0.0536'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0580, layer 6 is being updated for the 1-th time\n",
      "Epoch 20000, Loss: 1.5429e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0112', '0.0251', '0.0397', '0.0530'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0583, layer 6 is being updated for the 1-th time\n",
      "Epoch 20100, Loss: 1.3325e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0108', '0.0247', '0.0393', '0.0526'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0587, layer 6 is being updated for the 1-th time\n",
      "Epoch 20200, Loss: 1.5948e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0104', '0.0243', '0.0390', '0.0523'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0590, layer 6 is being updated for the 1-th time\n",
      "Epoch 20300, Loss: 1.4201e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0102', '0.0243', '0.0390', '0.0523'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0593, layer 6 is being updated for the 1-th time\n",
      "Epoch 20400, Loss: 1.8919e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0098', '0.0236', '0.0383', '0.0516'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0597, layer 6 is being updated for the 1-th time\n",
      "Epoch 20500, Loss: 1.4088e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0097', '0.0239', '0.0386', '0.0520'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0600, layer 6 is being updated for the 1-th time\n",
      "Epoch 20600, Loss: 1.5786e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0095', '0.0237', '0.0384', '0.0517'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0604, layer 6 is being updated for the 1-th time\n",
      "Epoch 20700, Loss: 1.1682e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0094', '0.0236', '0.0383', '0.0517'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0607, layer 6 is being updated for the 1-th time\n",
      "Epoch 20800, Loss: 1.3080e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0092', '0.0235', '0.0382', '0.0516'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0610, layer 6 is being updated for the 1-th time\n",
      "Epoch 20900, Loss: 1.3808e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0091', '0.0234', '0.0381', '0.0515'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0613, layer 6 is being updated for the 1-th time\n",
      "Epoch 21000, Loss: 1.6096e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0089', '0.0230', '0.0378', '0.0511'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0616, layer 6 is being updated for the 1-th time\n",
      "Epoch 21100, Loss: 1.5293e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0088', '0.0230', '0.0378', '0.0511'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0620, layer 6 is being updated for the 1-th time\n",
      "Epoch 21200, Loss: 1.3864e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0086', '0.0229', '0.0376', '0.0510'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0623, layer 6 is being updated for the 1-th time\n",
      "Epoch 21300, Loss: 1.0417e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0088', '0.0232', '0.0380', '0.0514'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0626, layer 6 is being updated for the 1-th time\n",
      "Epoch 21400, Loss: 1.3331e-04, L2 Relative_error: ['0.0011', '0.0025', '0.0035', '0.0049', '0.0061', '0.0065', '0.0087', '0.0230', '0.0377', '0.0511'], self.gammas: ['0.1000', '0.2000', '0.3000', '0.4000', '0.5000', '0.6000', '0.7000', '0.8000', '0.9000', '1.0000'], epsilon : 1.0e-02, lambda_phys : 1.0629, layer 6 is being updated for the 1-th time\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    T_max = 1\n",
    "    parameters_init = 50.0\n",
    "    n_stacked_mf_layers = 9\n",
    "    u_0 = 0.0\n",
    "    insize = 1  # Input size (t)\n",
    "    outsize = 1  # Output size (u)\n",
    "    h_sf_sizes = [40, 40, 40]\n",
    "    # Residual block hidden sizes\n",
    "    h_res_sizes = [40, 40, 40]\n",
    "    gammas_init = []\n",
    "    \n",
    "    for i in range(n_stacked_mf_layers+1):\n",
    "        gammas_init.append((i+1)/(n_stacked_mf_layers+1))\n",
    "    print(f'gammas_init : {gammas_init}')\n",
    "\n",
    "    # Initial condition\n",
    "    N_initial = 1\n",
    "    t_initial = tf.zeros(shape=(N_initial, 1), dtype=tf.float32)\n",
    "    u_initial = tf.convert_to_tensor([u_0] * N_initial, dtype=tf.float32)\n",
    "\n",
    "    # Create model\n",
    "    model = StackedMLP(insize, outsize, h_sf_sizes=h_sf_sizes, h_res_sizes=h_res_sizes,\n",
    "                       n_stacked_mf_layers=n_stacked_mf_layers, alpha_init=0.05, u_initial=u_initial)\n",
    "\n",
    "    optimizer_primal = [tf.keras.optimizers.legacy.Adam(learning_rate=1e-3)] + [tf.keras.optimizers.legacy.Adam(learning_rate=1e-4) for _ in range(n_stacked_mf_layers)]\n",
    "    optimizer_dual = tf.keras.optimizers.legacy.Adam(learning_rate=1e-3)\n",
    "\n",
    "    # Test points (optional for validation/testing)\n",
    "    n_steps = int(5e3)\n",
    "    u_tests = []\n",
    "    for i in range(n_stacked_mf_layers+1):\n",
    "        u_test, t_test = analytical_solution(n_steps, T_max=T_max, parameters_init=gammas_init[i]*parameters_init, u_0=u_0)\n",
    "        u_tests.append(u_test)\n",
    "    t_test = tf.reshape(t_test, (-1, 1))\n",
    "\n",
    "    # Create collocation points\n",
    "    N_collocation = 1000\n",
    "    t_collocation = tf.random.uniform(shape=(N_collocation, 1), minval=0, maxval=T_max)\n",
    "\n",
    "    # Create instance of Stacked Residual PINN\n",
    "    pinn = StackedResPINN(model, optimizer_primal, optimizer_dual, gammas_init=gammas_init, T_max=T_max, parameters_init=parameters_init)\n",
    "\n",
    "    # Train the model with test data for loss visualization\n",
    "    pinn.train(t_collocation, n_stacked_mf_layers, epochs=300000, t_test=t_test, u_test=u_tests, u_0=u_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,alpha_val in enumerate(model.alpha):\n",
    "    print(f\"alpha_{idx} = {alpha_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred_test, _, _ = model(t_test)\n",
    "u_true_test = u_tests[-1]\n",
    "\n",
    "absolute_error = tf.abs(u_pred_test - u_true_test).numpy().flatten()  # 1D\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(absolute_error, bins=30, alpha=0.75, label=\"x1\", edgecolor='black')\n",
    "plt.xlabel(\"Absolute Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Absolute Errors\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"Distribution of Absolute Errors.eps\", format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.boxplot(absolute_error, vert=True, labels=[\"x1\"])  # labels au singulier\n",
    "plt.ylabel('Absolute Error')\n",
    "plt.title('Error Boxplot')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"Absolute Error.eps\", format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_stacked_mf_layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m n_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m5e3\u001b[39m)\n\u001b[1;32m      2\u001b[0m u_tests \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mn_stacked_mf_layers\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      4\u001b[0m     u_test, t_test \u001b[38;5;241m=\u001b[39m analytical_solution(n_steps, T_max\u001b[38;5;241m=\u001b[39mT_max, parameters_init\u001b[38;5;241m=\u001b[39mpinn\u001b[38;5;241m.\u001b[39malphas[i]\u001b[38;5;241m*\u001b[39mparameters_init, u_0\u001b[38;5;241m=\u001b[39mu_0)\n\u001b[1;32m      5\u001b[0m     u_tests\u001b[38;5;241m.\u001b[39mappend(u_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_stacked_mf_layers' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plot the comparison of the output of each stack with the solution it tries to approximate\n",
    "\"\"\"\n",
    "# get the analytical solution each stack tries to approximate\n",
    "n_steps = int(5e3)\n",
    "u_tests = []\n",
    "for i in range(n_stacked_mf_layers+1):\n",
    "    u_test, t_test = analytical_solution(n_steps, T_max=T_max, parameters_init=pinn.gammas[i]*parameters_init, u_0=u_0)\n",
    "    u_tests.append(u_test)\n",
    "t_test = tf.reshape(t_test, (-1, 1))\n",
    "\n",
    "u_approx = []\n",
    "r_approx = []\n",
    "u_old_approx = []\n",
    "u_true = []\n",
    "t_test_np =tf.reshape(t_test, [-1]).numpy()\n",
    "sorted_indices = np.argsort(t_test_np)\n",
    "t_sorted = t_test_np[sorted_indices]\n",
    "\n",
    "# get the output of each stack and plot it\n",
    "for i in range(n_stacked_mf_layers+1):\n",
    "    u_i, u_old, r_i  = model(t_test, i=i)\n",
    "    \n",
    "    u_i_np = u_i.numpy()\n",
    "    u_i_sorted = u_i_np[sorted_indices]\n",
    "    u_approx.append(u_i_sorted)\n",
    "    \n",
    "    r_i_np = r_i.numpy()\n",
    "    r_i_sorted = r_i_np[sorted_indices]\n",
    "    r_approx.append(r_i_sorted)\n",
    "\n",
    "    u_old_np = u_old.numpy()\n",
    "    u_old_sorted = u_old_np[sorted_indices]\n",
    "    u_old_approx.append(u_old_sorted)\n",
    "\n",
    "    u_true_i_np = u_tests[i].numpy()\n",
    "    u_true_i_sorted = u_true_i_np[sorted_indices]\n",
    "    u_true.append(u_true_i_sorted)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(t_sorted, u_i_sorted, label=f'x_hat1_{i}')\n",
    "    plt.plot(t_sorted, u_true_i_sorted, linestyle='--', linewidth=1, label=f'x1_{i}')\n",
    "    plt.plot(t_sorted, r_i_sorted, linewidth=1, label=f'r_hat1_{i}', color='#A0A0A0')\n",
    "    plt.plot(t_sorted, u_old_sorted, linewidth=1.5, label=f'x_old_hat1_{i}', color='#AAAAAA')\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"State\")\n",
    "    plt.title(f\"u_approx_{i} vs u_test_{i}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"u_approx_{i} vs u_test_{i}.eps\", format='eps')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn-clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
